{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test.csv', 'train.csv', 'sample_submission.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.6/site-packages (1.0.1.post2)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.6/site-packages (0.2.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torchvision) (1.16.2)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from torchvision) (1.12.0)\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.6/site-packages (from torchvision) (5.1.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "1a6163dcdc773d5c64048b5b3a372736fac4640c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "import numbers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "4d4c24f6f7483fdbd780908596cf490060d8a648"
   },
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('../input/train.csv')\n",
    "test_df = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fae0172ee893f14999870cd28ef5e3117bcef689"
   },
   "source": [
    "Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "67216fd8696728ac17b8df4cb8a91ff49a91fda1"
   },
   "outputs": [],
   "source": [
    "class mydata(Dataset):\n",
    "     def __init__(self, file_path, \n",
    "                 transform = transforms.Compose([transforms.ToPILImage(), transforms.ToTensor(), \n",
    "                     transforms.Normalize(mean=(0.5,), std=(0.5,))])\n",
    "                ):\n",
    "        \n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        if len(df.columns) == n_pixels:\n",
    "            # test data\n",
    "            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n",
    "            self.y = None\n",
    "        else:\n",
    "            # training data\n",
    "            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n",
    "            self.y = torch.from_numpy(df.iloc[:,0].values)\n",
    "            \n",
    "        self.transform = transform\n",
    "    \n",
    "     def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "     def __getitem__(self, idx):\n",
    "        if self.y is not None:\n",
    "            return self.transform(self.X[idx]), self.y[idx]\n",
    "        else:\n",
    "            return self.transform(self.X[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a82bcfe9d716843893d2b3b140dcca5b61e7f61b"
   },
   "source": [
    "Random Rotation Transformation\n",
    "\n",
    "\n",
    "Randomly rotate the image. Available in upcoming torchvision but not now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "6f163d6cf92638c7cccb99814513638d05d54637"
   },
   "outputs": [],
   "source": [
    "class RandomRotation(object):\n",
    "    \"\"\"\n",
    "    https://github.com/pytorch/vision/tree/master/torchvision/transforms\n",
    "    Rotate the image by angle.\n",
    "    Args:\n",
    "        degrees (sequence or float or int): Range of degrees to select from.\n",
    "            If degrees is a number instead of sequence like (min, max), the range of degrees\n",
    "            will be (-degrees, +degrees).\n",
    "        resample ({PIL.Image.NEAREST, PIL.Image.BILINEAR, PIL.Image.BICUBIC}, optional):\n",
    "            An optional resampling filter.\n",
    "            See http://pillow.readthedocs.io/en/3.4.x/handbook/concepts.html#filters\n",
    "            If omitted, or if the image has mode \"1\" or \"P\", it is set to PIL.Image.NEAREST.\n",
    "        expand (bool, optional): Optional expansion flag.\n",
    "            If true, expands the output to make it large enough to hold the entire rotated image.\n",
    "            If false or omitted, make the output image the same size as the input image.\n",
    "            Note that the expand flag assumes rotation around the center and no translation.\n",
    "        center (2-tuple, optional): Optional center of rotation.\n",
    "            Origin is the upper left corner.\n",
    "            Default is the center of the image.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, degrees, resample=False, expand=False, center=None):\n",
    "        if isinstance(degrees, numbers.Number):\n",
    "            if degrees < 0:\n",
    "                raise ValueError(\"If degrees is a single number, it must be positive.\")\n",
    "            self.degrees = (-degrees, degrees)\n",
    "        else:\n",
    "            if len(degrees) != 2:\n",
    "                raise ValueError(\"If degrees is a sequence, it must be of len 2.\")\n",
    "            self.degrees = degrees\n",
    "\n",
    "        self.resample = resample\n",
    "        self.expand = expand\n",
    "        self.center = center\n",
    "\n",
    "    @staticmethod\n",
    "    def get_params(degrees):\n",
    "        \"\"\"Get parameters for ``rotate`` for a random rotation.\n",
    "        Returns:\n",
    "            sequence: params to be passed to ``rotate`` for random rotation.\n",
    "        \"\"\"\n",
    "        angle = np.random.uniform(degrees[0], degrees[1])\n",
    "\n",
    "        return angle\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "            img (PIL Image): Image to be rotated.\n",
    "        Returns:\n",
    "            PIL Image: Rotated image.\n",
    "        \"\"\"\n",
    "        \n",
    "        def rotate(img, angle, resample=False, expand=False, center=None):\n",
    "            \"\"\"Rotate the image by angle and then (optionally) translate it by (n_columns, n_rows)\n",
    "            Args:\n",
    "            img (PIL Image): PIL Image to be rotated.\n",
    "            angle ({float, int}): In degrees degrees counter clockwise order.\n",
    "            resample ({PIL.Image.NEAREST, PIL.Image.BILINEAR, PIL.Image.BICUBIC}, optional):\n",
    "            An optional resampling filter.\n",
    "            See http://pillow.readthedocs.io/en/3.4.x/handbook/concepts.html#filters\n",
    "            If omitted, or if the image has mode \"1\" or \"P\", it is set to PIL.Image.NEAREST.\n",
    "            expand (bool, optional): Optional expansion flag.\n",
    "            If true, expands the output image to make it large enough to hold the entire rotated image.\n",
    "            If false or omitted, make the output image the same size as the input image.\n",
    "            Note that the expand flag assumes rotation around the center and no translation.\n",
    "            center (2-tuple, optional): Optional center of rotation.\n",
    "            Origin is the upper left corner.\n",
    "            Default is the center of the image.\n",
    "            \"\"\"\n",
    "                \n",
    "            return img.rotate(angle, resample, expand, center)\n",
    "\n",
    "        angle = self.get_params(self.degrees)\n",
    "\n",
    "        return rotate(img, angle, self.resample, self.expand, self.center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9fbfccadca6d4ecae1a4bb6043a8aa2caaa1fe05"
   },
   "source": [
    "Random Vertical and Horizontal Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "2a595138822303c1772fec7cdfd98f54679630ec"
   },
   "outputs": [],
   "source": [
    "class RandomShift(object):\n",
    "    def __init__(self, shift):\n",
    "        self.shift = shift\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_params(shift):\n",
    "        \"\"\"Get parameters for ``rotate`` for a random rotation.\n",
    "        Returns:\n",
    "            sequence: params to be passed to ``rotate`` for random rotation.\n",
    "        \"\"\"\n",
    "        hshift, vshift = np.random.uniform(-shift, shift, size=2)\n",
    "\n",
    "        return hshift, vshift \n",
    "    def __call__(self, img):\n",
    "        hshift, vshift = self.get_params(self.shift)\n",
    "        \n",
    "        return img.transform(img.size, Image.AFFINE, (1,0,hshift,0,1,vshift), resample=Image.BICUBIC, fill=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "73f97c56221e43bfa15fc7b3e0ee5d929abe0606"
   },
   "source": [
    "Load the Data into Tensors\n",
    "\n",
    "For the training set, apply random rotation within the range of (-45, 45) degrees, shift by (-3, 3) pixels and normalize pixel values to [-1, 1]. For the test set, only apply nomalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "1ee9585424b77d3c642a8a1fdf3dd192f140da88"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "n_test = len(test_df)\n",
    "n_pixels = len(test_df.columns)\n",
    "train_dataset = mydata('../input/train.csv', transform= transforms.Compose(\n",
    "                            [transforms.ToPILImage(), RandomRotation(degrees=20), RandomShift(3),\n",
    "                             transforms.ToTensor(), transforms.Normalize(mean=(0.5,), std=(0.5,))]))\n",
    "test_dataset = mydata('../input/test.csv', )\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "c262e65edea82ce3f89b71dcd7190f5f1cd6ebfa"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "          \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "          \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p = 0.5),\n",
    "            nn.Linear(64 * 7 * 7, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p = 0.5),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p = 0.5),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "          \n",
    "        for m in self.features.children():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "        \n",
    "        for m in self.classifier.children():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "                \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x     \n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "0536f2ae2a0248df71a3c829833dc926fd9abada"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:45: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "253ac1a816dcf18ebd84dc5c3b29e53cef2f960e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5)\n",
      "    (1): Linear(in_features=3136, out_features=512, bias=True)\n",
      "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU(inplace)\n",
      "    (4): Dropout(p=0.5)\n",
      "    (5): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): ReLU(inplace)\n",
      "    (8): Dropout(p=0.5)\n",
      "    (9): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "44084377ac01a36cc667c47488d63aaf574e8a59"
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    exp_lr_scheduler.step()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (batch_idx + 1)% 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, (batch_idx + 1) * len(data), len(train_loader.dataset),\n",
    "                100. * (batch_idx + 1) / len(train_loader),loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "f9fc523dd2d0dcc2cba152ae39bbd006cdec16bf"
   },
   "outputs": [],
   "source": [
    "def evaluate(data_loader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for data, target in data_loader:\n",
    "        data, target = Variable(data,volatile=True), Variable(target)\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        \n",
    "        output = model(data)\n",
    "        \n",
    "        loss += F.cross_entropy(output, target, size_average=False).item()\n",
    "\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "    loss /= len(data_loader.dataset)\n",
    "        \n",
    "    print('\\nAverage loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\\n'.format(\n",
    "        loss, correct, len(data_loader.dataset),\n",
    "        100. * correct / len(data_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "ee412610c8e64229bc300d51aac08f084f8bde12",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [6400/42000 (15%)]\tLoss: 0.665881\n",
      "Train Epoch: 0 [12800/42000 (30%)]\tLoss: 0.252632\n",
      "Train Epoch: 0 [19200/42000 (46%)]\tLoss: 0.169396\n",
      "Train Epoch: 0 [25600/42000 (61%)]\tLoss: 0.470478\n",
      "Train Epoch: 0 [32000/42000 (76%)]\tLoss: 0.186681\n",
      "Train Epoch: 0 [38400/42000 (91%)]\tLoss: 0.455667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  import sys\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average loss: 0.1067, Accuracy: 40580/42000 (96.000%)\n",
      "\n",
      "Train Epoch: 1 [6400/42000 (15%)]\tLoss: 0.169890\n",
      "Train Epoch: 1 [12800/42000 (30%)]\tLoss: 0.136389\n",
      "Train Epoch: 1 [19200/42000 (46%)]\tLoss: 0.098573\n",
      "Train Epoch: 1 [25600/42000 (61%)]\tLoss: 0.284804\n",
      "Train Epoch: 1 [32000/42000 (76%)]\tLoss: 0.104317\n",
      "Train Epoch: 1 [38400/42000 (91%)]\tLoss: 0.056108\n",
      "\n",
      "Average loss: 0.0766, Accuracy: 40991/42000 (97.000%)\n",
      "\n",
      "Train Epoch: 2 [6400/42000 (15%)]\tLoss: 0.126850\n",
      "Train Epoch: 2 [12800/42000 (30%)]\tLoss: 0.020640\n",
      "Train Epoch: 2 [19200/42000 (46%)]\tLoss: 0.200954\n",
      "Train Epoch: 2 [25600/42000 (61%)]\tLoss: 0.054266\n",
      "Train Epoch: 2 [32000/42000 (76%)]\tLoss: 0.127467\n",
      "Train Epoch: 2 [38400/42000 (91%)]\tLoss: 0.013271\n",
      "\n",
      "Average loss: 0.0594, Accuracy: 41218/42000 (98.000%)\n",
      "\n",
      "Train Epoch: 3 [6400/42000 (15%)]\tLoss: 0.142059\n",
      "Train Epoch: 3 [12800/42000 (30%)]\tLoss: 0.052731\n",
      "Train Epoch: 3 [19200/42000 (46%)]\tLoss: 0.082832\n",
      "Train Epoch: 3 [25600/42000 (61%)]\tLoss: 0.089127\n",
      "Train Epoch: 3 [32000/42000 (76%)]\tLoss: 0.168568\n",
      "Train Epoch: 3 [38400/42000 (91%)]\tLoss: 0.060728\n",
      "\n",
      "Average loss: 0.0549, Accuracy: 41282/42000 (98.000%)\n",
      "\n",
      "Train Epoch: 4 [6400/42000 (15%)]\tLoss: 0.022818\n",
      "Train Epoch: 4 [12800/42000 (30%)]\tLoss: 0.188400\n",
      "Train Epoch: 4 [19200/42000 (46%)]\tLoss: 0.028269\n",
      "Train Epoch: 4 [25600/42000 (61%)]\tLoss: 0.141133\n",
      "Train Epoch: 4 [32000/42000 (76%)]\tLoss: 0.407954\n",
      "Train Epoch: 4 [38400/42000 (91%)]\tLoss: 0.062041\n",
      "\n",
      "Average loss: 0.0517, Accuracy: 41315/42000 (98.000%)\n",
      "\n",
      "Train Epoch: 5 [6400/42000 (15%)]\tLoss: 0.065936\n",
      "Train Epoch: 5 [12800/42000 (30%)]\tLoss: 0.091551\n",
      "Train Epoch: 5 [19200/42000 (46%)]\tLoss: 0.070826\n",
      "Train Epoch: 5 [25600/42000 (61%)]\tLoss: 0.047621\n",
      "Train Epoch: 5 [32000/42000 (76%)]\tLoss: 0.173104\n",
      "Train Epoch: 5 [38400/42000 (91%)]\tLoss: 0.076178\n",
      "\n",
      "Average loss: 0.0467, Accuracy: 41373/42000 (98.000%)\n",
      "\n",
      "Train Epoch: 6 [6400/42000 (15%)]\tLoss: 0.137234\n",
      "Train Epoch: 6 [12800/42000 (30%)]\tLoss: 0.124513\n",
      "Train Epoch: 6 [19200/42000 (46%)]\tLoss: 0.092365\n",
      "Train Epoch: 6 [25600/42000 (61%)]\tLoss: 0.049543\n",
      "Train Epoch: 6 [32000/42000 (76%)]\tLoss: 0.104394\n",
      "Train Epoch: 6 [38400/42000 (91%)]\tLoss: 0.027846\n",
      "\n",
      "Average loss: 0.0416, Accuracy: 41490/42000 (98.000%)\n",
      "\n",
      "Train Epoch: 7 [6400/42000 (15%)]\tLoss: 0.038335\n",
      "Train Epoch: 7 [12800/42000 (30%)]\tLoss: 0.071073\n",
      "Train Epoch: 7 [19200/42000 (46%)]\tLoss: 0.083070\n",
      "Train Epoch: 7 [25600/42000 (61%)]\tLoss: 0.191800\n",
      "Train Epoch: 7 [32000/42000 (76%)]\tLoss: 0.030511\n",
      "Train Epoch: 7 [38400/42000 (91%)]\tLoss: 0.005489\n",
      "\n",
      "Average loss: 0.0297, Accuracy: 41606/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 8 [6400/42000 (15%)]\tLoss: 0.023557\n",
      "Train Epoch: 8 [12800/42000 (30%)]\tLoss: 0.049270\n",
      "Train Epoch: 8 [19200/42000 (46%)]\tLoss: 0.052821\n",
      "Train Epoch: 8 [25600/42000 (61%)]\tLoss: 0.099283\n",
      "Train Epoch: 8 [32000/42000 (76%)]\tLoss: 0.007833\n",
      "Train Epoch: 8 [38400/42000 (91%)]\tLoss: 0.013993\n",
      "\n",
      "Average loss: 0.0270, Accuracy: 41637/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 9 [6400/42000 (15%)]\tLoss: 0.072822\n",
      "Train Epoch: 9 [12800/42000 (30%)]\tLoss: 0.025640\n",
      "Train Epoch: 9 [19200/42000 (46%)]\tLoss: 0.007713\n",
      "Train Epoch: 9 [25600/42000 (61%)]\tLoss: 0.090322\n",
      "Train Epoch: 9 [32000/42000 (76%)]\tLoss: 0.033911\n",
      "Train Epoch: 9 [38400/42000 (91%)]\tLoss: 0.025525\n",
      "\n",
      "Average loss: 0.0266, Accuracy: 41656/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 10 [6400/42000 (15%)]\tLoss: 0.012181\n",
      "Train Epoch: 10 [12800/42000 (30%)]\tLoss: 0.106623\n",
      "Train Epoch: 10 [19200/42000 (46%)]\tLoss: 0.053018\n",
      "Train Epoch: 10 [25600/42000 (61%)]\tLoss: 0.054228\n",
      "Train Epoch: 10 [32000/42000 (76%)]\tLoss: 0.096541\n",
      "Train Epoch: 10 [38400/42000 (91%)]\tLoss: 0.011965\n",
      "\n",
      "Average loss: 0.0234, Accuracy: 41693/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 11 [6400/42000 (15%)]\tLoss: 0.011483\n",
      "Train Epoch: 11 [12800/42000 (30%)]\tLoss: 0.016656\n",
      "Train Epoch: 11 [19200/42000 (46%)]\tLoss: 0.032509\n",
      "Train Epoch: 11 [25600/42000 (61%)]\tLoss: 0.003883\n",
      "Train Epoch: 11 [32000/42000 (76%)]\tLoss: 0.056066\n",
      "Train Epoch: 11 [38400/42000 (91%)]\tLoss: 0.008187\n",
      "\n",
      "Average loss: 0.0249, Accuracy: 41674/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 12 [6400/42000 (15%)]\tLoss: 0.044861\n",
      "Train Epoch: 12 [12800/42000 (30%)]\tLoss: 0.045194\n",
      "Train Epoch: 12 [19200/42000 (46%)]\tLoss: 0.079418\n",
      "Train Epoch: 12 [25600/42000 (61%)]\tLoss: 0.023294\n",
      "Train Epoch: 12 [32000/42000 (76%)]\tLoss: 0.086262\n",
      "Train Epoch: 12 [38400/42000 (91%)]\tLoss: 0.033779\n",
      "\n",
      "Average loss: 0.0223, Accuracy: 41712/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 13 [6400/42000 (15%)]\tLoss: 0.029697\n",
      "Train Epoch: 13 [12800/42000 (30%)]\tLoss: 0.085554\n",
      "Train Epoch: 13 [19200/42000 (46%)]\tLoss: 0.034209\n",
      "Train Epoch: 13 [25600/42000 (61%)]\tLoss: 0.064929\n",
      "Train Epoch: 13 [32000/42000 (76%)]\tLoss: 0.013312\n",
      "Train Epoch: 13 [38400/42000 (91%)]\tLoss: 0.244544\n",
      "\n",
      "Average loss: 0.0241, Accuracy: 41678/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 14 [6400/42000 (15%)]\tLoss: 0.010541\n",
      "Train Epoch: 14 [12800/42000 (30%)]\tLoss: 0.045021\n",
      "Train Epoch: 14 [19200/42000 (46%)]\tLoss: 0.104605\n",
      "Train Epoch: 14 [25600/42000 (61%)]\tLoss: 0.012723\n",
      "Train Epoch: 14 [32000/42000 (76%)]\tLoss: 0.014365\n",
      "Train Epoch: 14 [38400/42000 (91%)]\tLoss: 0.005846\n",
      "\n",
      "Average loss: 0.0216, Accuracy: 41714/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 15 [6400/42000 (15%)]\tLoss: 0.005161\n",
      "Train Epoch: 15 [12800/42000 (30%)]\tLoss: 0.089965\n",
      "Train Epoch: 15 [19200/42000 (46%)]\tLoss: 0.013005\n",
      "Train Epoch: 15 [25600/42000 (61%)]\tLoss: 0.039430\n",
      "Train Epoch: 15 [32000/42000 (76%)]\tLoss: 0.002731\n",
      "Train Epoch: 15 [38400/42000 (91%)]\tLoss: 0.003894\n",
      "\n",
      "Average loss: 0.0221, Accuracy: 41693/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 16 [6400/42000 (15%)]\tLoss: 0.087695\n",
      "Train Epoch: 16 [12800/42000 (30%)]\tLoss: 0.015902\n",
      "Train Epoch: 16 [19200/42000 (46%)]\tLoss: 0.003934\n",
      "Train Epoch: 16 [25600/42000 (61%)]\tLoss: 0.005526\n",
      "Train Epoch: 16 [32000/42000 (76%)]\tLoss: 0.139207\n",
      "Train Epoch: 16 [38400/42000 (91%)]\tLoss: 0.006036\n",
      "\n",
      "Average loss: 0.0226, Accuracy: 41706/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 17 [6400/42000 (15%)]\tLoss: 0.145188\n",
      "Train Epoch: 17 [12800/42000 (30%)]\tLoss: 0.051041\n",
      "Train Epoch: 17 [19200/42000 (46%)]\tLoss: 0.022149\n",
      "Train Epoch: 17 [25600/42000 (61%)]\tLoss: 0.094255\n",
      "Train Epoch: 17 [32000/42000 (76%)]\tLoss: 0.029486\n",
      "Train Epoch: 17 [38400/42000 (91%)]\tLoss: 0.119192\n",
      "\n",
      "Average loss: 0.0207, Accuracy: 41739/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 18 [6400/42000 (15%)]\tLoss: 0.006290\n",
      "Train Epoch: 18 [12800/42000 (30%)]\tLoss: 0.008154\n",
      "Train Epoch: 18 [19200/42000 (46%)]\tLoss: 0.010721\n",
      "Train Epoch: 18 [25600/42000 (61%)]\tLoss: 0.021344\n",
      "Train Epoch: 18 [32000/42000 (76%)]\tLoss: 0.045066\n",
      "Train Epoch: 18 [38400/42000 (91%)]\tLoss: 0.007256\n",
      "\n",
      "Average loss: 0.0210, Accuracy: 41720/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 19 [6400/42000 (15%)]\tLoss: 0.051188\n",
      "Train Epoch: 19 [12800/42000 (30%)]\tLoss: 0.014569\n",
      "Train Epoch: 19 [19200/42000 (46%)]\tLoss: 0.039211\n",
      "Train Epoch: 19 [25600/42000 (61%)]\tLoss: 0.111241\n",
      "Train Epoch: 19 [32000/42000 (76%)]\tLoss: 0.013823\n",
      "Train Epoch: 19 [38400/42000 (91%)]\tLoss: 0.002755\n",
      "\n",
      "Average loss: 0.0212, Accuracy: 41730/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 20 [6400/42000 (15%)]\tLoss: 0.003805\n",
      "Train Epoch: 20 [12800/42000 (30%)]\tLoss: 0.002110\n",
      "Train Epoch: 20 [19200/42000 (46%)]\tLoss: 0.036882\n",
      "Train Epoch: 20 [25600/42000 (61%)]\tLoss: 0.032546\n",
      "Train Epoch: 20 [32000/42000 (76%)]\tLoss: 0.012952\n",
      "Train Epoch: 20 [38400/42000 (91%)]\tLoss: 0.061171\n",
      "\n",
      "Average loss: 0.0210, Accuracy: 41734/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 21 [6400/42000 (15%)]\tLoss: 0.062123\n",
      "Train Epoch: 21 [12800/42000 (30%)]\tLoss: 0.002282\n",
      "Train Epoch: 21 [19200/42000 (46%)]\tLoss: 0.049869\n",
      "Train Epoch: 21 [25600/42000 (61%)]\tLoss: 0.005735\n",
      "Train Epoch: 21 [32000/42000 (76%)]\tLoss: 0.006906\n",
      "Train Epoch: 21 [38400/42000 (91%)]\tLoss: 0.030488\n",
      "\n",
      "Average loss: 0.0209, Accuracy: 41714/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 22 [6400/42000 (15%)]\tLoss: 0.004009\n",
      "Train Epoch: 22 [12800/42000 (30%)]\tLoss: 0.077669\n",
      "Train Epoch: 22 [19200/42000 (46%)]\tLoss: 0.072166\n",
      "Train Epoch: 22 [25600/42000 (61%)]\tLoss: 0.053731\n",
      "Train Epoch: 22 [32000/42000 (76%)]\tLoss: 0.050150\n",
      "Train Epoch: 22 [38400/42000 (91%)]\tLoss: 0.007833\n",
      "\n",
      "Average loss: 0.0208, Accuracy: 41727/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 23 [6400/42000 (15%)]\tLoss: 0.039421\n",
      "Train Epoch: 23 [12800/42000 (30%)]\tLoss: 0.001951\n",
      "Train Epoch: 23 [19200/42000 (46%)]\tLoss: 0.025809\n",
      "Train Epoch: 23 [25600/42000 (61%)]\tLoss: 0.139415\n",
      "Train Epoch: 23 [32000/42000 (76%)]\tLoss: 0.017964\n",
      "Train Epoch: 23 [38400/42000 (91%)]\tLoss: 0.042422\n",
      "\n",
      "Average loss: 0.0217, Accuracy: 41723/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 24 [6400/42000 (15%)]\tLoss: 0.032393\n",
      "Train Epoch: 24 [12800/42000 (30%)]\tLoss: 0.019307\n",
      "Train Epoch: 24 [19200/42000 (46%)]\tLoss: 0.002960\n",
      "Train Epoch: 24 [25600/42000 (61%)]\tLoss: 0.080212\n",
      "Train Epoch: 24 [32000/42000 (76%)]\tLoss: 0.011292\n",
      "Train Epoch: 24 [38400/42000 (91%)]\tLoss: 0.032138\n",
      "\n",
      "Average loss: 0.0218, Accuracy: 41714/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 25 [6400/42000 (15%)]\tLoss: 0.015497\n",
      "Train Epoch: 25 [12800/42000 (30%)]\tLoss: 0.045506\n",
      "Train Epoch: 25 [19200/42000 (46%)]\tLoss: 0.079690\n",
      "Train Epoch: 25 [25600/42000 (61%)]\tLoss: 0.052997\n",
      "Train Epoch: 25 [32000/42000 (76%)]\tLoss: 0.064608\n",
      "Train Epoch: 25 [38400/42000 (91%)]\tLoss: 0.049734\n",
      "\n",
      "Average loss: 0.0209, Accuracy: 41724/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 26 [6400/42000 (15%)]\tLoss: 0.129203\n",
      "Train Epoch: 26 [12800/42000 (30%)]\tLoss: 0.030466\n",
      "Train Epoch: 26 [19200/42000 (46%)]\tLoss: 0.016748\n",
      "Train Epoch: 26 [25600/42000 (61%)]\tLoss: 0.097102\n",
      "Train Epoch: 26 [32000/42000 (76%)]\tLoss: 0.040755\n",
      "Train Epoch: 26 [38400/42000 (91%)]\tLoss: 0.013707\n",
      "\n",
      "Average loss: 0.0203, Accuracy: 41735/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 27 [6400/42000 (15%)]\tLoss: 0.007815\n",
      "Train Epoch: 27 [12800/42000 (30%)]\tLoss: 0.073479\n",
      "Train Epoch: 27 [19200/42000 (46%)]\tLoss: 0.007512\n",
      "Train Epoch: 27 [25600/42000 (61%)]\tLoss: 0.029467\n",
      "Train Epoch: 27 [32000/42000 (76%)]\tLoss: 0.031683\n",
      "Train Epoch: 27 [38400/42000 (91%)]\tLoss: 0.022493\n",
      "\n",
      "Average loss: 0.0217, Accuracy: 41719/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 28 [6400/42000 (15%)]\tLoss: 0.017282\n",
      "Train Epoch: 28 [12800/42000 (30%)]\tLoss: 0.042074\n",
      "Train Epoch: 28 [19200/42000 (46%)]\tLoss: 0.056088\n",
      "Train Epoch: 28 [25600/42000 (61%)]\tLoss: 0.032647\n",
      "Train Epoch: 28 [32000/42000 (76%)]\tLoss: 0.073036\n",
      "Train Epoch: 28 [38400/42000 (91%)]\tLoss: 0.009826\n",
      "\n",
      "Average loss: 0.0216, Accuracy: 41712/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 29 [6400/42000 (15%)]\tLoss: 0.062845\n",
      "Train Epoch: 29 [12800/42000 (30%)]\tLoss: 0.059908\n",
      "Train Epoch: 29 [19200/42000 (46%)]\tLoss: 0.029829\n",
      "Train Epoch: 29 [25600/42000 (61%)]\tLoss: 0.031877\n",
      "Train Epoch: 29 [32000/42000 (76%)]\tLoss: 0.004725\n",
      "Train Epoch: 29 [38400/42000 (91%)]\tLoss: 0.057097\n",
      "\n",
      "Average loss: 0.0207, Accuracy: 41716/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 30 [6400/42000 (15%)]\tLoss: 0.010995\n",
      "Train Epoch: 30 [12800/42000 (30%)]\tLoss: 0.044695\n",
      "Train Epoch: 30 [19200/42000 (46%)]\tLoss: 0.131165\n",
      "Train Epoch: 30 [25600/42000 (61%)]\tLoss: 0.013989\n",
      "Train Epoch: 30 [32000/42000 (76%)]\tLoss: 0.017935\n",
      "Train Epoch: 30 [38400/42000 (91%)]\tLoss: 0.024949\n",
      "\n",
      "Average loss: 0.0215, Accuracy: 41716/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 31 [6400/42000 (15%)]\tLoss: 0.021837\n",
      "Train Epoch: 31 [12800/42000 (30%)]\tLoss: 0.046891\n",
      "Train Epoch: 31 [19200/42000 (46%)]\tLoss: 0.008321\n",
      "Train Epoch: 31 [25600/42000 (61%)]\tLoss: 0.018186\n",
      "Train Epoch: 31 [32000/42000 (76%)]\tLoss: 0.012340\n",
      "Train Epoch: 31 [38400/42000 (91%)]\tLoss: 0.075100\n",
      "\n",
      "Average loss: 0.0211, Accuracy: 41717/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 32 [6400/42000 (15%)]\tLoss: 0.054942\n",
      "Train Epoch: 32 [12800/42000 (30%)]\tLoss: 0.007795\n",
      "Train Epoch: 32 [19200/42000 (46%)]\tLoss: 0.005527\n",
      "Train Epoch: 32 [25600/42000 (61%)]\tLoss: 0.035601\n",
      "Train Epoch: 32 [32000/42000 (76%)]\tLoss: 0.082290\n",
      "Train Epoch: 32 [38400/42000 (91%)]\tLoss: 0.003645\n",
      "\n",
      "Average loss: 0.0209, Accuracy: 41708/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 33 [6400/42000 (15%)]\tLoss: 0.014652\n",
      "Train Epoch: 33 [12800/42000 (30%)]\tLoss: 0.045390\n",
      "Train Epoch: 33 [19200/42000 (46%)]\tLoss: 0.070834\n",
      "Train Epoch: 33 [25600/42000 (61%)]\tLoss: 0.070231\n",
      "Train Epoch: 33 [32000/42000 (76%)]\tLoss: 0.092775\n",
      "Train Epoch: 33 [38400/42000 (91%)]\tLoss: 0.082568\n",
      "\n",
      "Average loss: 0.0229, Accuracy: 41696/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 34 [6400/42000 (15%)]\tLoss: 0.010314\n",
      "Train Epoch: 34 [12800/42000 (30%)]\tLoss: 0.007244\n",
      "Train Epoch: 34 [19200/42000 (46%)]\tLoss: 0.053758\n",
      "Train Epoch: 34 [25600/42000 (61%)]\tLoss: 0.053239\n",
      "Train Epoch: 34 [32000/42000 (76%)]\tLoss: 0.027762\n",
      "Train Epoch: 34 [38400/42000 (91%)]\tLoss: 0.046457\n",
      "\n",
      "Average loss: 0.0204, Accuracy: 41723/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 35 [6400/42000 (15%)]\tLoss: 0.014193\n",
      "Train Epoch: 35 [12800/42000 (30%)]\tLoss: 0.026703\n",
      "Train Epoch: 35 [19200/42000 (46%)]\tLoss: 0.210653\n",
      "Train Epoch: 35 [25600/42000 (61%)]\tLoss: 0.029183\n",
      "Train Epoch: 35 [32000/42000 (76%)]\tLoss: 0.026576\n",
      "Train Epoch: 35 [38400/42000 (91%)]\tLoss: 0.018499\n",
      "\n",
      "Average loss: 0.0208, Accuracy: 41717/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 36 [6400/42000 (15%)]\tLoss: 0.073426\n",
      "Train Epoch: 36 [12800/42000 (30%)]\tLoss: 0.054340\n",
      "Train Epoch: 36 [19200/42000 (46%)]\tLoss: 0.075545\n",
      "Train Epoch: 36 [25600/42000 (61%)]\tLoss: 0.012429\n",
      "Train Epoch: 36 [32000/42000 (76%)]\tLoss: 0.029738\n",
      "Train Epoch: 36 [38400/42000 (91%)]\tLoss: 0.031789\n",
      "\n",
      "Average loss: 0.0204, Accuracy: 41747/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 37 [6400/42000 (15%)]\tLoss: 0.019943\n",
      "Train Epoch: 37 [12800/42000 (30%)]\tLoss: 0.007228\n",
      "Train Epoch: 37 [19200/42000 (46%)]\tLoss: 0.153156\n",
      "Train Epoch: 37 [25600/42000 (61%)]\tLoss: 0.048514\n",
      "Train Epoch: 37 [32000/42000 (76%)]\tLoss: 0.013087\n",
      "Train Epoch: 37 [38400/42000 (91%)]\tLoss: 0.031875\n",
      "\n",
      "Average loss: 0.0213, Accuracy: 41712/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 38 [6400/42000 (15%)]\tLoss: 0.083722\n",
      "Train Epoch: 38 [12800/42000 (30%)]\tLoss: 0.026338\n",
      "Train Epoch: 38 [19200/42000 (46%)]\tLoss: 0.011417\n",
      "Train Epoch: 38 [25600/42000 (61%)]\tLoss: 0.028679\n",
      "Train Epoch: 38 [32000/42000 (76%)]\tLoss: 0.025857\n",
      "Train Epoch: 38 [38400/42000 (91%)]\tLoss: 0.099820\n",
      "\n",
      "Average loss: 0.0213, Accuracy: 41720/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 39 [6400/42000 (15%)]\tLoss: 0.097195\n",
      "Train Epoch: 39 [12800/42000 (30%)]\tLoss: 0.062834\n",
      "Train Epoch: 39 [19200/42000 (46%)]\tLoss: 0.009783\n",
      "Train Epoch: 39 [25600/42000 (61%)]\tLoss: 0.008813\n",
      "Train Epoch: 39 [32000/42000 (76%)]\tLoss: 0.004033\n",
      "Train Epoch: 39 [38400/42000 (91%)]\tLoss: 0.265509\n",
      "\n",
      "Average loss: 0.0227, Accuracy: 41715/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 40 [6400/42000 (15%)]\tLoss: 0.105376\n",
      "Train Epoch: 40 [12800/42000 (30%)]\tLoss: 0.001322\n",
      "Train Epoch: 40 [19200/42000 (46%)]\tLoss: 0.077228\n",
      "Train Epoch: 40 [25600/42000 (61%)]\tLoss: 0.162085\n",
      "Train Epoch: 40 [32000/42000 (76%)]\tLoss: 0.036744\n",
      "Train Epoch: 40 [38400/42000 (91%)]\tLoss: 0.065201\n",
      "\n",
      "Average loss: 0.0214, Accuracy: 41722/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 41 [6400/42000 (15%)]\tLoss: 0.074262\n",
      "Train Epoch: 41 [12800/42000 (30%)]\tLoss: 0.026260\n",
      "Train Epoch: 41 [19200/42000 (46%)]\tLoss: 0.050276\n",
      "Train Epoch: 41 [25600/42000 (61%)]\tLoss: 0.041495\n",
      "Train Epoch: 41 [32000/42000 (76%)]\tLoss: 0.019466\n",
      "Train Epoch: 41 [38400/42000 (91%)]\tLoss: 0.047187\n",
      "\n",
      "Average loss: 0.0207, Accuracy: 41717/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 42 [6400/42000 (15%)]\tLoss: 0.103991\n",
      "Train Epoch: 42 [12800/42000 (30%)]\tLoss: 0.004922\n",
      "Train Epoch: 42 [19200/42000 (46%)]\tLoss: 0.027715\n",
      "Train Epoch: 42 [25600/42000 (61%)]\tLoss: 0.016995\n",
      "Train Epoch: 42 [32000/42000 (76%)]\tLoss: 0.030307\n",
      "Train Epoch: 42 [38400/42000 (91%)]\tLoss: 0.002782\n",
      "\n",
      "Average loss: 0.0211, Accuracy: 41722/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 43 [6400/42000 (15%)]\tLoss: 0.095685\n",
      "Train Epoch: 43 [12800/42000 (30%)]\tLoss: 0.017125\n",
      "Train Epoch: 43 [19200/42000 (46%)]\tLoss: 0.003667\n",
      "Train Epoch: 43 [25600/42000 (61%)]\tLoss: 0.005027\n",
      "Train Epoch: 43 [32000/42000 (76%)]\tLoss: 0.084821\n",
      "Train Epoch: 43 [38400/42000 (91%)]\tLoss: 0.021065\n",
      "\n",
      "Average loss: 0.0215, Accuracy: 41710/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 44 [6400/42000 (15%)]\tLoss: 0.091402\n",
      "Train Epoch: 44 [12800/42000 (30%)]\tLoss: 0.052908\n",
      "Train Epoch: 44 [19200/42000 (46%)]\tLoss: 0.003975\n",
      "Train Epoch: 44 [25600/42000 (61%)]\tLoss: 0.030359\n",
      "Train Epoch: 44 [32000/42000 (76%)]\tLoss: 0.002012\n",
      "Train Epoch: 44 [38400/42000 (91%)]\tLoss: 0.037193\n",
      "\n",
      "Average loss: 0.0203, Accuracy: 41723/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 45 [6400/42000 (15%)]\tLoss: 0.063468\n",
      "Train Epoch: 45 [12800/42000 (30%)]\tLoss: 0.063926\n",
      "Train Epoch: 45 [19200/42000 (46%)]\tLoss: 0.018565\n",
      "Train Epoch: 45 [25600/42000 (61%)]\tLoss: 0.106820\n",
      "Train Epoch: 45 [32000/42000 (76%)]\tLoss: 0.038616\n",
      "Train Epoch: 45 [38400/42000 (91%)]\tLoss: 0.018382\n",
      "\n",
      "Average loss: 0.0207, Accuracy: 41735/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 46 [6400/42000 (15%)]\tLoss: 0.032887\n",
      "Train Epoch: 46 [12800/42000 (30%)]\tLoss: 0.005868\n",
      "Train Epoch: 46 [19200/42000 (46%)]\tLoss: 0.024221\n",
      "Train Epoch: 46 [25600/42000 (61%)]\tLoss: 0.004950\n",
      "Train Epoch: 46 [32000/42000 (76%)]\tLoss: 0.009233\n",
      "Train Epoch: 46 [38400/42000 (91%)]\tLoss: 0.015528\n",
      "\n",
      "Average loss: 0.0211, Accuracy: 41725/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 47 [6400/42000 (15%)]\tLoss: 0.059442\n",
      "Train Epoch: 47 [12800/42000 (30%)]\tLoss: 0.006172\n",
      "Train Epoch: 47 [19200/42000 (46%)]\tLoss: 0.111847\n",
      "Train Epoch: 47 [25600/42000 (61%)]\tLoss: 0.024367\n",
      "Train Epoch: 47 [32000/42000 (76%)]\tLoss: 0.103225\n",
      "Train Epoch: 47 [38400/42000 (91%)]\tLoss: 0.025328\n",
      "\n",
      "Average loss: 0.0199, Accuracy: 41735/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 48 [6400/42000 (15%)]\tLoss: 0.145282\n",
      "Train Epoch: 48 [12800/42000 (30%)]\tLoss: 0.086464\n",
      "Train Epoch: 48 [19200/42000 (46%)]\tLoss: 0.110039\n",
      "Train Epoch: 48 [25600/42000 (61%)]\tLoss: 0.046570\n",
      "Train Epoch: 48 [32000/42000 (76%)]\tLoss: 0.153789\n",
      "Train Epoch: 48 [38400/42000 (91%)]\tLoss: 0.006730\n",
      "\n",
      "Average loss: 0.0210, Accuracy: 41729/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 49 [6400/42000 (15%)]\tLoss: 0.059294\n",
      "Train Epoch: 49 [12800/42000 (30%)]\tLoss: 0.051755\n",
      "Train Epoch: 49 [19200/42000 (46%)]\tLoss: 0.011785\n",
      "Train Epoch: 49 [25600/42000 (61%)]\tLoss: 0.006969\n",
      "Train Epoch: 49 [32000/42000 (76%)]\tLoss: 0.087358\n",
      "Train Epoch: 49 [38400/42000 (91%)]\tLoss: 0.092487\n",
      "\n",
      "Average loss: 0.0216, Accuracy: 41717/42000 (99.000%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train(epoch)\n",
    "    evaluate(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "4e67e0c1ddf14c8ec9897beeb1929a17e3904ae8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def prediciton(data_loader):\n",
    "    model.eval()\n",
    "    test_pred = torch.LongTensor()\n",
    "    \n",
    "    for i, data in enumerate(data_loader):\n",
    "        data = Variable(data, volatile=True)\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            \n",
    "        output = model(data)\n",
    "        \n",
    "        pred = output.cpu().data.max(1, keepdim=True)[1]\n",
    "        test_pred = torch.cat((test_pred, pred), dim=0)\n",
    "        \n",
    "    return test_pred\n",
    "test_pred = prediciton(test_loader)\n",
    "out_df = pd.DataFrame(np.c_[np.arange(1, len(test_dataset)+1)[:,None], test_pred.numpy()], \n",
    "                      columns=['ImageId', 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "f9bfc21615fb3483c9f74e42fbf8dc9a6056aefe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "test_pred = prediciton(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "5406a9b0bc78a107266fbe87f7b82d9a31bd0405"
   },
   "outputs": [],
   "source": [
    "out_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
